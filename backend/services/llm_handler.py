import requests
import json
import re
import os


class LLMHandler:
    def __init__(self, dict_path="../data/cc-cedict.txt"):
        # 1. Load Dictionary (Fast & Deterministic)
        self.dictionary = self._load_cedict(dict_path)
        
        # 2. LLM Config
        self.ollama_url = "http://localhost:11434/api/generate"
        self.chat_model = "qwen2.5:1.5b"
        self.feedback_model = "qwen2.5:3b"

    # -------------------------------------------------------
    # DICTIONARY LOADING
    # -------------------------------------------------------
    def _load_cedict(self, path):
        current_dir = os.path.dirname(os.path.abspath(__file__))
        full_path = os.path.join(current_dir, path)
        
        if not os.path.exists(full_path):
            print(f"Warning: Dictionary file {full_path} not found. Running in LLM-only mode.")
            return {}
            
        print("Loading Dictionary... (takes ~1s)")
        cedict = {}
        with open(full_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.startswith('#') or line.startswith('%') or not line.strip(): 
                    continue
                
                try:
                    bracket_start = line.find('[')
                    bracket_end = line.find(']')
                    if bracket_start == -1 or bracket_end == -1: 
                        continue
                    
                    parts = line[:bracket_start].strip().split()
                    if len(parts) < 2: 
                        continue
                    
                    traditional = parts[0]
                    simplified = parts[1]
                    pinyin = line[bracket_start+1:bracket_end].strip()
                    
                    meanings_raw = line[bracket_end+1:].strip().strip('/')
                    meanings = [m.strip() for m in meanings_raw.split('/') if m.strip()]
                    
                    entry = {
                        "simplified": simplified,
                        "traditional": traditional,
                        "pinyin": pinyin,
                        "definitions": meanings
                    }

                    # Index by simplified Chinese (primary key)
                    if simplified not in cedict:
                        cedict[simplified] = entry
                    
                    # Also index by traditional (for lookup flexibility)
                    if traditional != simplified and traditional not in cedict:
                        cedict[traditional] = entry

                except Exception:
                    continue
        
        print(f"Dictionary loaded: {len(cedict)} entries.")
        return cedict

    # -------------------------------------------------------
    # PUBLIC: Get Response (Conversation)
    # -------------------------------------------------------
    def get_response(self, user_message, conversation_history):
        try:
            context = self._build_context(conversation_history)

            system_prompt = (
                "<system>"
                "ä½ æ˜¯ä¸€ä½æ¸©æŸ”ã€å‹å–„çš„ä¸­æ–‡ä¼šè¯è€å¸ˆã€‚"
                "ä½ è¦ä½¿ç”¨éå¸¸è‡ªç„¶çš„ä¸­æ–‡ï¼ˆç±»ä¼¼æ—¥å¸¸å¯¹è¯ï¼ŒHSK2-4 çš„éš¾åº¦ï¼‰ã€‚"
                "ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ä½¿ç”¨è€…ç»ƒä¹ ä¸­æ–‡å£è¯­ã€‚\n"
                "è§„åˆ™ï¼š\n"
                "1. æ°¸è¿œåªç”¨ä¸­æ–‡å›ç­”ã€‚\n"
                "2. å¦‚æœç”¨æˆ·çš„ä¸­æ–‡ä¸è‡ªç„¶ï¼Œä½ çš„å›ç­”ä¸­ç»™å‡ºè‡ªç„¶ã€æ­£ç¡®çš„è¡¨è¾¾ï¼Œä½†ä¸è¦ç›´æ¥æŒ‡å‡ºé”™è¯¯ã€‚\n"
                "3. å¦‚æœç”¨æˆ·æ··åˆè‹±æ–‡ï¼Œä½ å¯ä»¥è‡ªç„¶åœ°ç»™å‡ºä¸­æ–‡å¯¹åº”è¯ã€‚\n"
                "4. æ¯æ¬¡å›å¤ä¿æŒç®€çŸ­ä½†è‡ªç„¶ï¼Œå¹¶æå‡ºä¸€ä¸ªç®€å•çš„è¿½é—®ã€‚\n"
                "5. ä¸è¦è§£é‡Šè¯­æ³•ï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚ã€‚\n"
                "</system>"
            )

            prompt = (
                f"{system_prompt}\n"
                f"<conversation>\n"
                f"{context}\n"
                f"<user>{user_message}</user>\n"
                f"<assistant>"
            )

            response = self._call_ollama(self.chat_model, prompt, 0.9, 0.9, keep_alive="5m")

            if response.status_code != 200:
                return "æŠ±æ­‰ï¼Œæˆ‘å¥½åƒé‡åˆ°ä¸€ç‚¹é—®é¢˜ï¼Œä½ å¯ä»¥å†è¯´ä¸€æ¬¡å—ï¼Ÿ"

            result_text = self._safe_parse_response(response).strip()

            if not self._looks_like_mandarin(result_text):
                result_text = "æˆ‘å†è¯´ä¸€éï¼š" + result_text

            return result_text

        except Exception as e:
            print(f"LLM Error: {e}")
            return "ç³»ç»Ÿå¥½åƒè¿ä¸ä¸Šï¼Œä½ å¯ä»¥å†è¯•ä¸€æ¬¡å—ï¼Ÿ"

    # -------------------------------------------------------
    # PUBLIC: Correct Sentence (NEW APPROACH)
    # -------------------------------------------------------
    def correct_sentence(self, broken_sentence):
        """
        NEW: Natural correction with smart highlighting.
        
        Returns: {
            "corrected": "è‡ªç„¶çš„ä¸­æ–‡å¥å­",
            "highlights": [
                {
                    "word": "ä¸­æ–‡è¯",
                    "meaning": "English meaning",
                    "why": "ä¸ºä»€ä¹ˆå€¼å¾—å­¦ä¹ ",
                    "category": "new_vocab|measure_word|collocation|idiom"
                }
            ],
            "note": "æ•´ä½“è¯„ä»·ï¼ˆå¯é€‰ï¼‰"
        }
        """
        
        # Extract English words to hint to the LLM
        english_words = re.findall(r'[a-zA-Z]+', broken_sentence)
        english_hint = f"\næ³¨æ„ï¼šç”¨æˆ·ç”¨è‹±æ–‡è¯´äº†è¿™äº›è¯ï¼š{', '.join(english_words)}" if english_words else ""
        
        # Build the new prompt
        prompt = f"""ä½ æ˜¯ç»éªŒä¸°å¯Œçš„ä¸­æ–‡è€å¸ˆã€‚å­¦ç”Ÿï¼ˆä¸­çº§æ°´å¹³ï¼ŒHSK 3-4ï¼‰è¯´äº†ï¼š

"{broken_sentence}"{english_hint}

ä»»åŠ¡ï¼š
1. æ”¹æˆæ¯è¯­è€…ä¼šè¯´çš„è‡ªç„¶å¥å­
2. æ ‡æ³¨å€¼å¾—å­¦ä¹ çš„è¯æ±‡ï¼ˆæ–°è¯ã€æ­é…ã€é‡è¯ã€ä¹ è¯­ç­‰ï¼‰

è§„åˆ™ï¼š
- ä¸è¦é€å­—ç¿»è¯‘ï¼è¦è¯´æ¯è¯­è€…çœŸæ­£ä¼šè¯´çš„è¯
- ä»”ç»†ç†è§£å¥å­ç»“æ„å’Œè¯­å¢ƒï¼ˆæ³¨æ„ä¸€è¯å¤šä¹‰ã€åŒå½¢å¼‚ä¹‰è¯ï¼‰
- ä¹ è¯­ã€é—®å€™è¯­è¦ç”¨åœ°é“è¡¨è¾¾ï¼ˆä¾‹å¦‚ï¼š"hello people" â†’ "å¤§å®¶å¥½"ï¼Œä¸æ˜¯"ä½ å¥½äººä»¬"ï¼‰
- é«˜äº®æ‰€æœ‰å€¼å¾—æ³¨æ„çš„è¯æ±‡ï¼š
  * ç”¨æˆ·ç”¨è‹±æ–‡è¯´çš„è¯ï¼ˆè¯´æ˜ä»–ä»¬ä¸çŸ¥é“ä¸­æ–‡æ€ä¹ˆè¯´ï¼‰
  * ä¸­é«˜çº§è¯æ±‡ï¼ˆHSK 3+ï¼‰
  * é‡è¯ã€æ­é…ã€ä¹ è¯­
  * ä¸è¦æ ‡æ³¨"æˆ‘"ã€"çš„"ã€"æ˜¯"è¿™ç§æœ€åŸºç¡€çš„è¯
- é‡è¯å¦‚æœç”¨é”™ï¼Œè¦æ ‡æ³¨æ­£ç¡®çš„é‡è¯
- å¦‚æœå¥å­å·²ç»å¾ˆè‡ªç„¶ï¼Œcorrected å¯ä»¥è·ŸåŸå¥ç›¸åŒ

è¾“å‡ºJSONï¼ˆæ— å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
  "corrected": "è‡ªç„¶æµç•…çš„ä¸­æ–‡å¥å­",
  "highlights": [
    {{
      "word": "é«˜äº®çš„ä¸­æ–‡è¯",
      "meaning": "è‹±æ–‡å«ä¹‰",
      "why": "ä¸ºä»€ä¹ˆå€¼å¾—å­¦ä¹ ï¼ˆä¾‹å¦‚ï¼šå¸¸ç”¨æ­é…ã€æ­£å¼ç”¨è¯­ã€é‡è¯ç­‰ï¼‰",
      "category": "new_vocab|collocation|measure_word|idiom"
    }}
  ],
  "note": "æ•´ä½“è¯„ä»·ï¼ˆå¯é€‰ï¼Œå¦‚æœå¥å­æ”¹åŠ¨è¾ƒå¤§æ‰å†™ï¼‰"
}}

ç¤ºä¾‹1 - æ··åˆä¸­è‹±æ–‡ï¼š
è¾“å…¥: "æˆ‘æƒ³bookä¸€ä¸ªrestaurantï¼Œä½ æœ‰recommendationå—ï¼Ÿ"
è¾“å‡º: {{
  "corrected": "æˆ‘æƒ³é¢„è®¢ä¸€å®¶é¤å…ï¼Œä½ æœ‰æ¨èçš„å—ï¼Ÿ",
  "highlights": [
    {{"word": "é¢„è®¢", "meaning": "to reserve/book", "why": "æ­£å¼åœºåˆç”¨è¯", "category": "new_vocab"}},
    {{"word": "ä¸€å®¶é¤å…", "meaning": "a restaurant", "why": "é¤å…çš„é‡è¯æ˜¯'å®¶'", "category": "measure_word"}},
    {{"word": "æ¨è", "meaning": "recommend", "why": "å¸¸ç”¨åŠ¨è¯", "category": "new_vocab"}}
  ],
  "note": ""
}}

ç¤ºä¾‹2 - è¯­æ³•/è¯­åºé”™è¯¯ï¼š
è¾“å…¥: "æˆ‘æ˜¨å¤©å»äº†å•†åº—å¾ˆå¤šäºº"
è¾“å‡º: {{
  "corrected": "æˆ‘æ˜¨å¤©å»äº†å•†åº—ï¼Œäººå¾ˆå¤š",
  "highlights": [
    {{"word": "äººå¾ˆå¤š", "meaning": "very crowded (lit: people very many)", "why": "æ­£ç¡®è¯­åºï¼šä¸»è¯­+å¾ˆ+å½¢å®¹è¯", "category": "collocation"}}
  ],
  "note": "éœ€è¦ç”¨é€—å·åˆ†éš”ä¸¤ä¸ªä¿¡æ¯"
}}

ç¤ºä¾‹3 - å·²ç»å¾ˆè‡ªç„¶ï¼š
è¾“å…¥: "æˆ‘ä»Šå¤©å¾ˆç´¯ï¼Œæƒ³æ—©ç‚¹ç¡è§‰"
è¾“å‡º: {{
  "corrected": "æˆ‘ä»Šå¤©å¾ˆç´¯ï¼Œæƒ³æ—©ç‚¹ç¡è§‰",
  "highlights": [],
  "note": "è¯´å¾—å¾ˆè‡ªç„¶ï¼"
}}

ç¤ºä¾‹4 - çº¯è‹±æ–‡ï¼ˆä¹ è¯­è¡¨è¾¾ï¼‰ï¼š
è¾“å…¥: "hello people"
è¾“å‡º: {{
  "corrected": "å¤§å®¶å¥½",
  "highlights": [
    {{"word": "å¤§å®¶å¥½", "meaning": "hello everyone (idiomatic greeting)", "why": "ä¹ æƒ¯ç”¨è¯­ï¼Œæ¯”'ä½ å¥½äººä»¬'æ›´è‡ªç„¶", "category": "idiom"}}
  ],
  "note": ""
}}

ç¤ºä¾‹5 - çº¯è‹±æ–‡ï¼ˆç›´æ¥ç¿»è¯‘ï¼‰ï¼š
è¾“å…¥: "I want to learn Chinese"
è¾“å‡º: {{
  "corrected": "æˆ‘æƒ³å­¦ä¸­æ–‡",
  "highlights": [
    {{"word": "å­¦", "meaning": "to learn/study", "why": "åŸºç¡€åŠ¨è¯", "category": "new_vocab"}},
    {{"word": "ä¸­æ–‡", "meaning": "Chinese language", "why": "ä¸'æ±‰è¯­'åŒä¹‰ï¼Œæ›´å£è¯­åŒ–", "category": "new_vocab"}}
  ],
  "note": ""
}}

ç¤ºä¾‹6 - çº¯è‹±æ–‡ï¼ˆæ³¨æ„ä¸€è¯å¤šä¹‰ï¼‰ï¼š
è¾“å…¥: "I hit a bat with a bat"
è¾“å‡º: {{
  "corrected": "æˆ‘ç”¨çƒæ£’æ‰“äº†ä¸€åªè™è ",
  "highlights": [
    {{"word": "çƒæ£’", "meaning": "baseball bat (sports equipment)", "why": "è¿åŠ¨å™¨æ", "category": "new_vocab"}},
    {{"word": "è™è ", "meaning": "bat (animal)", "why": "åŠ¨ç‰©åç§°", "category": "new_vocab"}},
    {{"word": "ç”¨...æ‰“", "meaning": "to hit with (using...)", "why": "å¸¸ç”¨ç»“æ„", "category": "collocation"}}
  ],
  "note": "æ³¨æ„ï¼šbat æœ‰ä¸¤ä¸ªæ„æ€ï¼ˆçƒæ£’/è™è ï¼‰"
}}

ç°åœ¨å¤„ç†ï¼š
"{broken_sentence}"

è¾“å‡ºJSONï¼š"""

        try:
            # Unload chat model, load feedback model
            requests.post(self.ollama_url, json={"model": self.chat_model, "keep_alive": 0})
            print("â†’ Loading 3B Feedback Model...")
            
            response = self._call_ollama(self.feedback_model, prompt, 0.3, 0.9, 0)
            raw = self._safe_parse_response(response).strip()
            
            # Clean and parse JSON
            parsed = self._parse_json_or_fallback(raw)
            
            # Validate structure
            if not parsed.get('corrected'):
                parsed['corrected'] = broken_sentence
            if 'highlights' not in parsed:
                parsed['highlights'] = []
            if 'note' not in parsed:
                parsed['note'] = ''
            
            print(f"âœ… Corrected: {parsed['corrected']}")
            print(f"ğŸ“š Highlights: {len(parsed['highlights'])} items")
            
            return parsed
            
        except Exception as e:
            print(f"[ERROR] Correction failed: {e}")
            return {
                "corrected": broken_sentence,
                "highlights": [],
                "note": f"Error: {str(e)}"
            }

    # -------------------------------------------------------
    # HELPERS
    # -------------------------------------------------------
    def _build_context(self, history):
        """Converts conversation history into XML-tag structure."""
        formatted = []
        for msg in history[-8:]:
            if msg["role"] == "user":
                formatted.append(f"<user>{msg['content']}</user>")
            else:
                formatted.append(f"<assistant>{msg['content']}</assistant>")
        return "\n".join(formatted)

    def _safe_parse_response(self, response):
        """Modified for non-streaming JSON mode"""
        try:
            # Since stream=False, the entire body is one JSON object
            data = response.json()
            return data.get("response", "")
        except Exception as e:
            print(f"Parsing error: {e}")
            return ""

    def _looks_like_mandarin(self, text):
        """Check if output contains Chinese characters."""
        return bool(re.search(r"[\u4e00-\u9fff]", text))

    def _parse_json_or_fallback(self, text):
        """Try to parse JSON from model output, with fallback."""
        text = text.strip()
        text = text.replace("```json", "").replace("```", "")
        
        try:
            return json.loads(text)
        except:
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            return {
                "corrected": text,
                "highlights": [],
                "note": "è§£æé”™è¯¯"
            }
            
    def _call_ollama(self, model, prompt, temperature=0.2, top_p=0.9, keep_alive="5m"):
        """Unified caller to handle VRAM memory swap."""
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "keep_alive": keep_alive,
            "options": {
                "num_ctx": 2048,
                "temperature": temperature,
                "top_p": top_p,
            }
        }
        return requests.post(self.ollama_url, json=payload)